{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBLFPY1rQY9F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score # Import precision_score, recall_score, f1_score\n",
        "from joblib import load\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Attention\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Attention, GlobalAveragePooling1D # Import GlobalAveragePooling1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "814wOvL5P7T_",
        "outputId": "99bc86e0-6ad3-4e0c-f0fb-bca89917ace2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "Model loaded!\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/bilstm_attention_model.keras\"\n",
        "print(\"Loading model...\")\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "print(\"Model loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-UZxfyYQ0C7",
        "outputId": "ac6828ae-25a8-4f3e-a872-5d7ceb30e522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
          ]
        }
      ],
      "source": [
        "#loading data and data pre-processing\n",
        "train_file_path = '/content/train-00000-of-00001.parquet'\n",
        "test_file_path = '/content/test-00000-of-00001.parquet'\n",
        "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
        "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
        "\n",
        "X_train = train_df['sentence'].tolist()\n",
        "y_train = train_df['relation'].tolist()\n",
        "X_test = test_df['sentence'].tolist()\n",
        "y_test = test_df['relation'].tolist()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "glove_path = \"/content/glove.6B.100d.txt\"\n",
        "embedding_dim = 100\n",
        "\n",
        "word2vec = {}\n",
        "with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        word2vec[word] = vector\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    vector = word2vec.get(word)\n",
        "    if vector is not None:\n",
        "        embedding_matrix[i] = vector\n",
        "\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "train_features = model.predict(X_train_pad)\n",
        "test_features = model.predict(X_test_pad)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXMykPV3R6_d",
        "outputId": "b7195f39-cceb-45e4-885d-1b961e1c990c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation on Test Set:\n",
            "Accuracy: 0.7118\n",
            "Precision: 0.6537\n",
            "Recall: 0.7025\n",
            "F1 Score: 0.6725\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85       134\n",
            "           1       0.85      0.87      0.86       194\n",
            "           2       0.68      0.75      0.71       162\n",
            "           3       0.63      0.65      0.64       150\n",
            "           4       0.73      0.92      0.81       153\n",
            "           5       0.77      0.69      0.73        39\n",
            "           6       0.83      0.84      0.83       291\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.74      0.84      0.79       211\n",
            "           9       0.81      0.83      0.82        47\n",
            "          10       0.45      0.45      0.45        22\n",
            "          11       0.57      0.72      0.64       134\n",
            "          12       0.56      0.62      0.59        32\n",
            "          13       0.75      0.88      0.81       201\n",
            "          14       0.74      0.87      0.80       210\n",
            "          15       0.66      0.80      0.73        51\n",
            "          16       0.72      0.80      0.76       108\n",
            "          17       0.60      0.69      0.64       123\n",
            "          18       0.50      0.22      0.31       454\n",
            "\n",
            "    accuracy                           0.71      2717\n",
            "   macro avg       0.65      0.70      0.67      2717\n",
            "weighted avg       0.69      0.71      0.69      2717\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "#Model evaluation\n",
        "svm_model = SVC(kernel='linear', class_weight='balanced')\n",
        "svm_model.fit(train_features, y_train_encoded)\n",
        "\n",
        "\n",
        "y_pred = svm_model.predict(test_features)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "precision = precision_score(y_test_encoded, y_pred, average='macro')\n",
        "recall = recall_score(y_test_encoded, y_pred, average='macro')\n",
        "f1 = f1_score(y_test_encoded, y_pred, average='macro')\n",
        "\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYiIwrm0rg6k",
        "outputId": "f1e19043-e5c7-4001-a659-732d8b7de202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "\n",
            " Relation Extraction Model Ready! Type 'exit' to stop.\n",
            "\n",
            "Enter a sentence:\n",
            "The <e1>author</e1> of a keygen uses a <e2>disassembler</e2> to look at the raw assembly code.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            " Predicted Relation ID: 11, Name: Instrument-Agency(e2,e1)\n",
            "\n",
            "Enter a sentence:\n",
            "A misty <e1>ridge</e1> uprises from the <e2>surge</e2>.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            " Predicted Relation ID: 8, Name: Entity-Origin(e1,e2)\n",
            "\n",
            "Enter a sentence:\n",
            "The <e1>student</e1> <e2>association</e2> is the voice of the undergraduate student population of the State University of New York at Buffalo.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            " Predicted Relation ID: 12, Name: Member-Collection(e1,e2)\n",
            "\n",
            "Enter a sentence:\n",
            "exit\n",
            "Exiting program...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "#  Load the trained model\n",
        "model_path = \"/content/bilstm_attention_model.keras\"\n",
        "print(\"Loading model...\")\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer_path = \"/content/tokenizer.pkl\"\n",
        "with open(tokenizer_path, 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#  Manually define relation ID mappings for SemEval 2010 Task 8\n",
        "relation_id_to_label = {\n",
        "          0: \"Cause-Effect(e1,e2)\",\n",
        "          1: \"Cause-Effect(e2,e1)\",\n",
        "          2: \"Component-Whole(e1,e2)\",\n",
        "          3: \"Component-Whole(e2,e1)\",\n",
        "          4: \"Content-Container(e1,e2)\",\n",
        "          5: \"Content-Container(e2,e1)\",\n",
        "          6: \"Entity-Destination(e1,e2)\",\n",
        "          7: \"Entity-Destination(e2,e1)\",\n",
        "          8: \"Entity-Origin(e1,e2)\",\n",
        "          9: \"Entity-Origin(e2,e1)\",\n",
        "          10: \"Instrument-Agency(e1,e2)\",\n",
        "          11: \"Instrument-Agency(e2,e1)\",\n",
        "          12: \"Member-Collection(e1,e2)\",\n",
        "          13: \"Member-Collection(e2,e1)\",\n",
        "          14: \"Message-Topic(e1,e2)\",\n",
        "          15: \"Message-Topic(e2,e1)\",\n",
        "          16: \"Product-Producer(e1,e2)\",\n",
        "          17: \"Product-Producer(e2,e1)\",\n",
        "          18: \"Other\"\n",
        "\n",
        "}\n",
        "\n",
        "#  Define function for relation extraction\n",
        "def extract_relation_keras(sentence, model, tokenizer, relation_id_to_label, max_len=100):\n",
        "    \"\"\"\n",
        "    Extracts the relation using the trained Keras model.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The input sentence.\n",
        "        model (tf.keras.Model): The trained Keras model.\n",
        "        tokenizer (Tokenizer): The tokenizer used for training.\n",
        "        relation_id_to_label (dict): Dictionary mapping relation IDs to relation names.\n",
        "        max_len (int): Maximum sequence length.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (relation_id, relation_name)\n",
        "    \"\"\"\n",
        "    # Tokenize and pad the sentence\n",
        "    sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
        "\n",
        "    # Predict relation\n",
        "    features = model.predict(padded_sequence)\n",
        "    predicted_relation_id = np.argmax(features, axis=1)[0]  # Get predicted class index\n",
        "\n",
        "    # Retrieve the relation name\n",
        "    predicted_relation_name = relation_id_to_label.get(predicted_relation_id, \"Unknown Relation\")\n",
        "\n",
        "    return predicted_relation_id, predicted_relation_name\n",
        "\n",
        "#  Real-time user input loop\n",
        "print(\"\\n Relation Extraction Model Ready! Type 'exit' to stop.\")\n",
        "\n",
        "while True:\n",
        "    user_sentence = input(\"\\nEnter a sentence:\\n\")\n",
        "\n",
        "    if user_sentence.lower() == \"exit\":\n",
        "        print(\"Exiting program...\")\n",
        "        break\n",
        "\n",
        "    relation_id, relation_name = extract_relation_keras(user_sentence, model, tokenizer, relation_id_to_label)\n",
        "\n",
        "    print(f\" Predicted Relation ID: {relation_id}, Name: {relation_name}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}