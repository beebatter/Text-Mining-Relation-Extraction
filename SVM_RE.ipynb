{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1740017709888,
     "user": {
      "displayName": "Xingjian Yuan",
      "userId": "04192760108139199616"
     },
     "user_tz": 0
    },
    "id": "QN4yEnDwfI38",
    "outputId": "26870056-e314-4ecc-9cfe-e425b155a4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  relation\n",
      "0  The system as described above has its greatest...         3\n",
      "1  The <e1>child</e1> was carefully wrapped and b...        18\n",
      "2  The <e1>author</e1> of a keygen uses a <e2>dis...        11\n",
      "3  A misty <e1>ridge</e1> uprises from the <e2>su...        18\n",
      "4  The <e1>student</e1> <e2>association</e2> is t...        12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设Parquet文件名为'semeval_2010_task_8.parquet'，并且位于当前目录下\n",
    "file_path = '/content/train-00000-of-00001.parquet'\n",
    "\n",
    "# 使用pandas的read_parquet函数读取Parquet文件\n",
    "df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "\n",
    "# 显示DataFrame的前几行\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17337,
     "status": "ok",
     "timestamp": 1740017784883,
     "user": {
      "displayName": "Xingjian Yuan",
      "userId": "04192760108139199616"
     },
     "user_tz": 0
    },
    "id": "l7doAsmwI2Ve",
    "outputId": "5733535d-5c64-49c6-d5c8-73b81fba2cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76        75\n",
      "           1       0.79      0.64      0.70       170\n",
      "           2       0.46      0.38      0.42       126\n",
      "           3       0.73      0.27      0.39       120\n",
      "           4       0.76      0.68      0.71       109\n",
      "           5       0.77      0.48      0.59        48\n",
      "           6       0.73      0.80      0.77       194\n",
      "           8       0.43      0.63      0.51       142\n",
      "           9       0.62      0.16      0.25        32\n",
      "          10       0.60      0.12      0.20        25\n",
      "          11       0.72      0.36      0.48       109\n",
      "          12       1.00      0.05      0.10        19\n",
      "          13       0.55      0.57      0.56       157\n",
      "          14       0.57      0.30      0.40       128\n",
      "          15       0.78      0.19      0.30        37\n",
      "          16       0.53      0.33      0.41        81\n",
      "          17       0.63      0.11      0.19       105\n",
      "          18       0.25      0.56      0.34       323\n",
      "\n",
      "    accuracy                           0.49      2000\n",
      "   macro avg       0.66      0.40      0.45      2000\n",
      "weighted avg       0.59      0.49      0.49      2000\n",
      "\n",
      "Accuracy: 0.4915\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 加载数据集\n",
    "file_path = '/content/train-00000-of-00001.parquet'\n",
    "df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "\n",
    "# 数据预处理\n",
    "# 假设数据集中有一个名为'text'的列包含文本，一个名为'relation'的列包含关系标签\n",
    "X = df['sentence']\n",
    "y = df['relation']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# 创建一个管道，首先使用TF-IDF向量化文本，然后使用SVM进行分类\n",
    "model = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 打印分类报告\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 打印准确率\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4939,
     "status": "ok",
     "timestamp": 1740017972723,
     "user": {
      "displayName": "Xingjian Yuan",
      "userId": "04192760108139199616"
     },
     "user_tz": 0
    },
    "id": "5nHBfLWgJmww",
    "outputId": "8c123aa1-50ed-4795-abd9-f841b25bb251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92       134\n",
      "           1       0.95      0.90      0.92       194\n",
      "           2       0.86      0.78      0.82       162\n",
      "           3       0.95      0.80      0.87       150\n",
      "           4       0.89      0.93      0.91       153\n",
      "           5       1.00      0.74      0.85        39\n",
      "           6       0.91      0.96      0.93       291\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.83      0.93      0.88       211\n",
      "           9       1.00      0.68      0.81        47\n",
      "          10       1.00      0.36      0.53        22\n",
      "          11       0.96      0.75      0.85       134\n",
      "          12       1.00      0.38      0.55        32\n",
      "          13       0.93      0.78      0.85       201\n",
      "          14       0.95      0.78      0.86       210\n",
      "          15       1.00      0.69      0.81        51\n",
      "          16       0.94      0.73      0.82       108\n",
      "          17       0.99      0.70      0.82       123\n",
      "          18       0.57      0.89      0.70       454\n",
      "\n",
      "    accuracy                           0.83      2717\n",
      "   macro avg       0.88      0.72      0.77      2717\n",
      "weighted avg       0.87      0.83      0.84      2717\n",
      "\n",
      "Accuracy: 0.8325358851674641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 加载训练数据集\n",
    "train_file_path = '/content/test-00000-of-00001.parquet'\n",
    "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
    "\n",
    "# 数据预处理\n",
    "X_train = train_df['sentence']\n",
    "y_train = train_df['relation']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "# 这里我们只做演示，实际中应该使用交叉验证或独立的验证集\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# 创建一个管道，首先使用TF-IDF向量化文本，然后使用SVM进行分类\n",
    "model = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# 加载测试数据集\n",
    "test_file_path = '/content/test-00000-of-00001.parquet'\n",
    "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
    "\n",
    "# 对测试数据进行相同的预处理步骤（如果需要）\n",
    "X_test = test_df['sentence']\n",
    "\n",
    "# 使用训练好的模型对测试数据进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 如果测试数据包含真实标签，评估模型性能\n",
    "# 假设测试数据集包含真实标签\n",
    "y_test = test_df['relation']\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMuhZTwToprfWslPqju0aNO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
