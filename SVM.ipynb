{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fOX0wWpaJDo6"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **First testing for reading dataset**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NTglkDHZ3rpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#  set path of document\n",
        "file_path = '/content/train-00000-of-00001.parquet'\n",
        "\n",
        "# using function read_parquet in pandas to read Parquert documents\n",
        "df = pd.read_parquet(file_path, engine='pyarrow')\n",
        "\n",
        "# show first few lines in the  dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "QN4yEnDwfI38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f96388b-de6f-4632-fac1-8db20fd91874"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            sentence  relation\n",
            "0  The system as described above has its greatest...         3\n",
            "1  The <e1>child</e1> was carefully wrapped and b...        18\n",
            "2  The <e1>author</e1> of a keygen uses a <e2>dis...        11\n",
            "3  A misty <e1>ridge</e1> uprises from the <e2>su...        18\n",
            "4  The <e1>student</e1> <e2>association</e2> is t...        12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# 1.initial version, using CountVectorizer for feature extraction (with poor performance)**"
      ],
      "metadata": {
        "id": "kk4V_YFk379_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score # Import precision_score, recall_score, f1_score\n",
        "\n",
        "# read training set\n",
        "train_file_path = '/content/train-00000-of-00001.parquet'\n",
        "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
        "\n",
        "# reading test set\n",
        "test_file_path = '/content/test-00000-of-00001.parquet'\n",
        "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
        "\n",
        "#  extracting features(sentences) and labels(relations)\n",
        "X_train = train_df['sentence']\n",
        "y_train = train_df['relation']\n",
        "\n",
        "X_test = test_df['sentence']\n",
        "y_test = test_df['relation']\n",
        "\n",
        "\n",
        "# creating pipepline, with using CountVectorizer to translate contexts into word frequncy, then using SVM to classify\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# print the result of classification\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# print the scores\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LRAwM3qQw7n",
        "outputId": "53f755d1-7f2f-44e2-85ec-ab7097452d85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.67      0.76       134\n",
            "           1       0.75      0.82      0.79       194\n",
            "           2       0.41      0.47      0.44       162\n",
            "           3       0.40      0.29      0.33       150\n",
            "           4       0.62      0.71      0.66       153\n",
            "           5       0.71      0.64      0.68        39\n",
            "           6       0.70      0.81      0.75       291\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.60      0.72      0.65       211\n",
            "           9       0.73      0.23      0.35        47\n",
            "          10       0.38      0.27      0.32        22\n",
            "          11       0.51      0.40      0.45       134\n",
            "          12       0.46      0.19      0.27        32\n",
            "          13       0.49      0.56      0.52       201\n",
            "          14       0.57      0.47      0.51       210\n",
            "          15       0.56      0.37      0.45        51\n",
            "          16       0.41      0.34      0.37       108\n",
            "          17       0.42      0.23      0.30       123\n",
            "          18       0.29      0.37      0.33       454\n",
            "\n",
            "    accuracy                           0.53      2717\n",
            "   macro avg       0.52      0.45      0.47      2717\n",
            "weighted avg       0.53      0.53      0.52      2717\n",
            "\n",
            "Model Evaluation on Test Set:\n",
            "Accuracy: 0.5252\n",
            "Precision: 0.5207\n",
            "Recall: 0.4502\n",
            "F1 Score: 0.4694\n",
            "\n",
            "Detailed Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.using IF-IDF for Text Augmentation**"
      ],
      "metadata": {
        "id": "RZXJYM8C4Dje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "train_file_path = '/content/train-00000-of-00001.parquet'\n",
        "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
        "\n",
        "test_file_path = '/content/test-00000-of-00001.parquet'\n",
        "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
        "\n",
        "X_train = train_df['sentence']\n",
        "y_train = train_df['relation']\n",
        "\n",
        "X_test = test_df['sentence']\n",
        "y_test = test_df['relation']\n",
        "\n",
        "# creating pipepline, with using IF-IDF to vectorize texts, then using SVM to classify\n",
        "model = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# print the scores\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAWK0neyq2q-",
        "outputId": "d190f004-fd00-4d70-ee68-7025eb349c7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.68      0.79       134\n",
            "           1       0.82      0.81      0.81       194\n",
            "           2       0.49      0.51      0.50       162\n",
            "           3       0.59      0.25      0.36       150\n",
            "           4       0.69      0.69      0.69       153\n",
            "           5       0.70      0.59      0.64        39\n",
            "           6       0.74      0.82      0.78       291\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.61      0.76      0.68       211\n",
            "           9       0.90      0.19      0.32        47\n",
            "          10       0.50      0.14      0.21        22\n",
            "          11       0.60      0.37      0.46       134\n",
            "          12       0.33      0.03      0.06        32\n",
            "          13       0.56      0.56      0.56       201\n",
            "          14       0.66      0.42      0.51       210\n",
            "          15       0.74      0.33      0.46        51\n",
            "          16       0.49      0.35      0.41       108\n",
            "          17       0.42      0.11      0.17       123\n",
            "          18       0.27      0.51      0.36       454\n",
            "\n",
            "    accuracy                           0.54      2717\n",
            "   macro avg       0.58      0.43      0.46      2717\n",
            "weighted avg       0.59      0.54      0.53      2717\n",
            "\n",
            "Model Evaluation on Test Set:\n",
            "Accuracy: 0.5377\n",
            "Precision: 0.5815\n",
            "Recall: 0.4277\n",
            "F1 Score: 0.4606\n",
            "\n",
            "Detailed Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compared with countvectorizer, using IF-IDF\n",
        "has a little improvement in Accuracy (around 1%)"
      ],
      "metadata": {
        "id": "XqJSlDSRRnVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.including grid search: trying different kernal function parameters(C, gamma values); kernel functions**"
      ],
      "metadata": {
        "id": "XzN1S6AU4MUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "train_file_path = '/content/train-00000-of-00001.parquet'\n",
        "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
        "\n",
        "test_file_path = '/content/test-00000-of-00001.parquet'\n",
        "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
        "\n",
        "X_train = train_df['sentence']\n",
        "y_train = train_df['relation']\n",
        "\n",
        "X_test = test_df['sentence']\n",
        "y_test = test_df['relation']\n",
        "\n",
        "pipeline = make_pipeline(TfidfVectorizer(), SVC())\n",
        "\n",
        "# defining the parameters grid search used in SVM model\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],  # SVM regularization parameter\n",
        "    'svc__gamma': [0.1, 1, 10],  # Kernel function parameter\n",
        "    'svc__kernel': ['linear', 'rbf', 'poly']  # Kernel function type\n",
        "}\n",
        "\n",
        "# creating the grid-search object\n",
        "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1_macro')\n",
        "\n",
        "# fit training data into the grid_serach object\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# output the optimal parameters and scores\n",
        "print(f'The best parameter is {grid_search.best_params_}')\n",
        "print(f'The best score is {grid_search.best_score_}')\n",
        "print(f'The best estimator is {grid_search.best_estimator_}')\n",
        "\n",
        "# predicting using the optimal model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# evaluating performance of model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "# print the scores\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQJpdtgjk2wy",
        "outputId": "45f2b27e-5905-4970-b525-9428b747c445"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameter is {'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'linear'}\n",
            "The best score is 0.49765151341862734\n",
            "The best estimator is Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
            "                ('svc', SVC(C=10, gamma=0.1, kernel='linear'))])\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.72      0.80       134\n",
            "           1       0.79      0.84      0.81       194\n",
            "           2       0.41      0.54      0.47       162\n",
            "           3       0.41      0.31      0.35       150\n",
            "           4       0.67      0.70      0.68       153\n",
            "           5       0.66      0.59      0.62        39\n",
            "           6       0.74      0.82      0.78       291\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.63      0.71      0.67       211\n",
            "           9       0.79      0.32      0.45        47\n",
            "          10       0.43      0.27      0.33        22\n",
            "          11       0.55      0.40      0.46       134\n",
            "          12       0.62      0.16      0.25        32\n",
            "          13       0.57      0.56      0.56       201\n",
            "          14       0.59      0.50      0.54       210\n",
            "          15       0.66      0.41      0.51        51\n",
            "          16       0.43      0.37      0.40       108\n",
            "          17       0.48      0.21      0.29       123\n",
            "          18       0.28      0.39      0.33       454\n",
            "\n",
            "    accuracy                           0.54      2717\n",
            "   macro avg       0.56      0.46      0.49      2717\n",
            "weighted avg       0.56      0.54      0.54      2717\n",
            "\n",
            "Model Evaluation on Test Set:\n",
            "Accuracy: 0.5410\n",
            "Precision: 0.5579\n",
            "Recall: 0.4631\n",
            "F1 Score: 0.4895\n",
            "\n",
            "Detailed Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared with the initial SVM method,\n",
        "there are improvments in those scores\n",
        "from test sets by adding grid search to\n",
        "search best parameters. (improved appx 1% in Accuracy)"
      ],
      "metadata": {
        "id": "rf0xC8WP9vW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.using BiLSTM+Attention to extract features from texts,then input extracted features to SVM for relation extraction**"
      ],
      "metadata": {
        "id": "FuuZ2AyU4Rh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score # Import precision_score, recall_score, f1_score\n",
        "from joblib import load\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Attention\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Attention, GlobalAveragePooling1D # Import GlobalAveragePooling1D\n",
        "\n",
        "train_file_path = '/content/train-00000-of-00001.parquet'\n",
        "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
        "\n",
        "test_file_path = '/content/test-00000-of-00001.parquet'\n",
        "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
        "\n",
        "X_train = train_df['sentence']\n",
        "y_train = train_df['relation']\n",
        "\n",
        "X_test = test_df['sentence']\n",
        "y_test = test_df['relation']\n",
        "\n",
        "\n",
        "# translate texts into sequences using Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# fill the sequences\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# defining BiLSTM + Attention model\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(input_dim=10000, output_dim=100)(input_layer)\n",
        "bilstm_layer = Bidirectional(LSTM(units=64, return_sequences=True))(embedding_layer)\n",
        "attention_layer = tf.keras.layers.Attention()([bilstm_layer, bilstm_layer])\n",
        "\n",
        "# Add GlobalAveragePooling1D layer to get a fixed-length vector\n",
        "pooling_layer = GlobalAveragePooling1D()(attention_layer)\n",
        "output_layer = Dense(units=len(y_train.unique()), activation='softmax')(pooling_layer) # Connect to pooling layer\n",
        "\n",
        "# building model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# training deep learning model\n",
        "model.fit(X_train_pad, y_train, epochs=30, validation_split=0.2)\n",
        "\n",
        "# extracting features using the deep learning model\n",
        "train_features = model.predict(X_train_pad)\n",
        "test_features = model.predict(X_test_pad)\n",
        "\n",
        "# classification using SVM\n",
        "svm_model = make_pipeline(SVC(kernel='linear'))\n",
        "svm_model.fit(train_features, y_train)\n",
        "\n",
        "# predication and evaluation\n",
        "y_pred = svm_model.predict(test_features)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VRFcJgAMk41",
        "outputId": "b523c65b-65fe-4663-81fe-d01d1cecf674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.1464 - loss: 2.7398 - val_accuracy: 0.2394 - val_loss: 2.6894\n",
            "Epoch 2/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.1879 - loss: 2.5893 - val_accuracy: 0.2456 - val_loss: 2.4474\n",
            "Epoch 3/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.3566 - loss: 2.0723 - val_accuracy: 0.3137 - val_loss: 2.1892\n",
            "Epoch 4/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5469 - loss: 1.4240 - val_accuracy: 0.3369 - val_loss: 2.1386\n",
            "Epoch 5/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7118 - loss: 0.9616 - val_accuracy: 0.3981 - val_loss: 2.0761\n",
            "Epoch 6/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8199 - loss: 0.6329 - val_accuracy: 0.3925 - val_loss: 2.3312\n",
            "Epoch 7/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8866 - loss: 0.4203 - val_accuracy: 0.4050 - val_loss: 2.4239\n",
            "Epoch 8/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9322 - loss: 0.2665 - val_accuracy: 0.3856 - val_loss: 2.6885\n",
            "Epoch 9/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9517 - loss: 0.1944 - val_accuracy: 0.4144 - val_loss: 2.9118\n",
            "Epoch 10/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9709 - loss: 0.1345 - val_accuracy: 0.4094 - val_loss: 2.7301\n",
            "Epoch 11/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9816 - loss: 0.0873 - val_accuracy: 0.4069 - val_loss: 3.1124\n",
            "Epoch 12/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9833 - loss: 0.0731 - val_accuracy: 0.4112 - val_loss: 3.2654\n",
            "Epoch 13/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9851 - loss: 0.0727 - val_accuracy: 0.4181 - val_loss: 3.3007\n",
            "Epoch 14/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9908 - loss: 0.0504 - val_accuracy: 0.4325 - val_loss: 3.2456\n",
            "Epoch 15/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9919 - loss: 0.0427 - val_accuracy: 0.4106 - val_loss: 3.6518\n",
            "Epoch 16/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9931 - loss: 0.0380 - val_accuracy: 0.4212 - val_loss: 3.5623\n",
            "Epoch 17/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9943 - loss: 0.0294 - val_accuracy: 0.4281 - val_loss: 3.4602\n",
            "Epoch 18/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0215 - val_accuracy: 0.4006 - val_loss: 3.8237\n",
            "Epoch 19/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9904 - loss: 0.0393 - val_accuracy: 0.4175 - val_loss: 3.8129\n",
            "Epoch 20/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0125 - val_accuracy: 0.3938 - val_loss: 3.6031\n",
            "Epoch 21/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9912 - loss: 0.0356 - val_accuracy: 0.4219 - val_loss: 3.5546\n",
            "Epoch 22/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0127 - val_accuracy: 0.4212 - val_loss: 3.7250\n",
            "Epoch 23/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9963 - loss: 0.0163 - val_accuracy: 0.3975 - val_loss: 4.0512\n",
            "Epoch 24/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9862 - loss: 0.0501 - val_accuracy: 0.4025 - val_loss: 3.6557\n",
            "Epoch 25/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9961 - loss: 0.0176 - val_accuracy: 0.4206 - val_loss: 3.8668\n",
            "Epoch 26/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9949 - loss: 0.0206 - val_accuracy: 0.4137 - val_loss: 3.7885\n",
            "Epoch 27/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9986 - loss: 0.0123 - val_accuracy: 0.4075 - val_loss: 4.1064\n",
            "Epoch 28/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9943 - loss: 0.0280 - val_accuracy: 0.4200 - val_loss: 3.7085\n",
            "Epoch 29/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9983 - loss: 0.0075 - val_accuracy: 0.4169 - val_loss: 3.9543\n",
            "Epoch 30/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.4087 - val_loss: 4.1440\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "Model Evaluation on Test Set:\n",
            "Accuracy: 0.5679\n",
            "Precision: 0.5260\n",
            "Recall: 0.5064\n",
            "F1 Score: 0.5112\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       134\n",
            "           1       0.79      0.82      0.81       194\n",
            "           2       0.53      0.52      0.53       162\n",
            "           3       0.46      0.41      0.43       150\n",
            "           4       0.71      0.72      0.72       153\n",
            "           5       0.72      0.59      0.65        39\n",
            "           6       0.80      0.78      0.79       291\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.71      0.71      0.71       211\n",
            "           9       0.54      0.60      0.57        47\n",
            "          10       0.20      0.23      0.21        22\n",
            "          11       0.46      0.42      0.44       134\n",
            "          12       0.15      0.34      0.21        32\n",
            "          13       0.68      0.75      0.71       201\n",
            "          14       0.66      0.44      0.53       210\n",
            "          15       0.51      0.41      0.46        51\n",
            "          16       0.48      0.42      0.45       108\n",
            "          17       0.39      0.32      0.35       123\n",
            "          18       0.32      0.39      0.35       454\n",
            "\n",
            "    accuracy                           0.57      2717\n",
            "   macro avg       0.53      0.51      0.51      2717\n",
            "weighted avg       0.59      0.57      0.57      2717\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the glove file\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifx1ZFzRBNqe",
        "outputId": "6b38c73c-20e1-42fb-f181-87bc9f1a44ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-27 01:28:22--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-02-27 01:28:22--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-02-27 01:28:23--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 3m 52s  \n",
            "\n",
            "2025-02-27 01:32:16 (3.55 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Glove word vectors in the pre-processing step has good\n",
        "improvement in Accuracy compared with the previous version (appx 10%)."
      ],
      "metadata": {
        "id": "3IkOvgO54pyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.adding pre-trained word vectors from GloVe to help the model understand meanings of words, with class weights**"
      ],
      "metadata": {
        "id": "N3rLOgth6IE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "train_file_path = '/content/train-00000-of-00001.parquet'\n",
        "test_file_path = '/content/test-00000-of-00001.parquet'\n",
        "train_df = pd.read_parquet(train_file_path, engine='pyarrow')\n",
        "test_df = pd.read_parquet(test_file_path, engine='pyarrow')\n",
        "\n",
        "X_train = train_df['sentence'].tolist()\n",
        "y_train = train_df['relation'].tolist()\n",
        "X_test = test_df['sentence'].tolist()\n",
        "y_test = test_df['relation'].tolist()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "glove_path = \"/content/glove.6B.100d.txt\"\n",
        "embedding_dim = 100\n",
        "\n",
        "#adding wordnet\n",
        "word2vec = {}\n",
        "with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        word2vec[word] = vector\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    vector = word2vec.get(word)\n",
        "    if vector is not None:\n",
        "        embedding_matrix[i] = vector\n",
        "\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim,\n",
        "                            weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "bilstm_layer = Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.2))(embedding_layer)\n",
        "attention_layer = tf.keras.layers.Attention()([bilstm_layer, bilstm_layer])\n",
        "pooling_layer = GlobalAveragePooling1D()(attention_layer)\n",
        "dropout_layer = Dropout(0.3)(pooling_layer)\n",
        "output_layer = Dense(units=len(np.unique(y_train_encoded)), activation='softmax')(dropout_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_train_pad, y_train_encoded, epochs=30, batch_size=32, validation_split=0.2,\n",
        "           class_weight=class_weight_dict, callbacks=[early_stopping])\n",
        "\n",
        "train_features = model.predict(X_train_pad)\n",
        "test_features = model.predict(X_test_pad)\n",
        "\n",
        "svm_model = SVC(kernel='linear', class_weight='balanced')\n",
        "svm_model.fit(train_features, y_train_encoded)\n",
        "\n",
        "\n",
        "y_pred = svm_model.predict(test_features)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "precision = precision_score(y_test_encoded, y_pred, average='macro')\n",
        "recall = recall_score(y_test_encoded, y_pred, average='macro')\n",
        "f1 = f1_score(y_test_encoded, y_pred, average='macro')\n",
        "\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyAqZ2NypvTV",
        "outputId": "11898491-9c48-4ef9-952d-f7e0d53be1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.0927 - loss: 2.9485 - val_accuracy: 0.1544 - val_loss: 2.7244\n",
            "Epoch 2/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.2347 - loss: 2.9395 - val_accuracy: 0.1975 - val_loss: 2.5646\n",
            "Epoch 3/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3026 - loss: 2.1149 - val_accuracy: 0.1713 - val_loss: 2.7135\n",
            "Epoch 4/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3074 - loss: 1.9959 - val_accuracy: 0.1663 - val_loss: 2.5977\n",
            "Epoch 5/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3208 - loss: 2.0134 - val_accuracy: 0.2225 - val_loss: 2.4391\n",
            "Epoch 6/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.3766 - loss: 1.8352 - val_accuracy: 0.3006 - val_loss: 2.2891\n",
            "Epoch 7/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4372 - loss: 1.6425 - val_accuracy: 0.3319 - val_loss: 2.2382\n",
            "Epoch 8/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4371 - loss: 1.7973 - val_accuracy: 0.3431 - val_loss: 2.1961\n",
            "Epoch 9/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4692 - loss: 1.5456 - val_accuracy: 0.3825 - val_loss: 2.0276\n",
            "Epoch 10/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.5339 - loss: 1.3477 - val_accuracy: 0.3831 - val_loss: 1.9922\n",
            "Epoch 11/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.5647 - loss: 1.2109 - val_accuracy: 0.4344 - val_loss: 1.8538\n",
            "Epoch 12/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5929 - loss: 1.1233 - val_accuracy: 0.4325 - val_loss: 1.8441\n",
            "Epoch 13/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6094 - loss: 1.0392 - val_accuracy: 0.4369 - val_loss: 1.7921\n",
            "Epoch 14/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6265 - loss: 0.9665 - val_accuracy: 0.4600 - val_loss: 1.6936\n",
            "Epoch 15/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6364 - loss: 0.9457 - val_accuracy: 0.4613 - val_loss: 1.7118\n",
            "Epoch 16/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6474 - loss: 0.9106 - val_accuracy: 0.4825 - val_loss: 1.6248\n",
            "Epoch 17/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6587 - loss: 0.8291 - val_accuracy: 0.4875 - val_loss: 1.6383\n",
            "Epoch 18/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6722 - loss: 0.8038 - val_accuracy: 0.5056 - val_loss: 1.5469\n",
            "Epoch 19/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6979 - loss: 0.7705 - val_accuracy: 0.4888 - val_loss: 1.5924\n",
            "Epoch 20/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6906 - loss: 0.7512 - val_accuracy: 0.5206 - val_loss: 1.4925\n",
            "Epoch 21/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6995 - loss: 0.7005 - val_accuracy: 0.5288 - val_loss: 1.5405\n",
            "Epoch 22/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7184 - loss: 0.6519 - val_accuracy: 0.5225 - val_loss: 1.5784\n",
            "Epoch 23/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7093 - loss: 0.6615 - val_accuracy: 0.5325 - val_loss: 1.4327\n",
            "Epoch 24/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7337 - loss: 0.5960 - val_accuracy: 0.5269 - val_loss: 1.4984\n",
            "Epoch 25/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7287 - loss: 0.6085 - val_accuracy: 0.5325 - val_loss: 1.4921\n",
            "Epoch 26/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7340 - loss: 0.5907 - val_accuracy: 0.5387 - val_loss: 1.4567\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Model Evaluation on Test Set:\n",
            "Accuracy: 0.6842\n",
            "Precision: 0.6193\n",
            "Recall: 0.6919\n",
            "F1 Score: 0.6439\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84       134\n",
            "           1       0.86      0.85      0.85       194\n",
            "           2       0.66      0.75      0.70       162\n",
            "           3       0.56      0.58      0.57       150\n",
            "           4       0.72      0.87      0.79       153\n",
            "           5       0.78      0.74      0.76        39\n",
            "           6       0.82      0.84      0.83       291\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.72      0.83      0.77       211\n",
            "           9       0.80      0.77      0.78        47\n",
            "          10       0.30      0.68      0.42        22\n",
            "          11       0.55      0.60      0.57       134\n",
            "          12       0.37      0.72      0.49        32\n",
            "          13       0.76      0.94      0.84       201\n",
            "          14       0.75      0.80      0.78       210\n",
            "          15       0.67      0.75      0.70        51\n",
            "          16       0.69      0.78      0.73       108\n",
            "          17       0.55      0.57      0.56       123\n",
            "          18       0.43      0.17      0.25       454\n",
            "\n",
            "    accuracy                           0.68      2717\n",
            "   macro avg       0.62      0.69      0.64      2717\n",
            "weighted avg       0.66      0.68      0.66      2717\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.poor performance in relation no 7, try eliminating it and see the model performance**"
      ],
      "metadata": {
        "id": "IRJlsGyl6weV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "excluded_classes = [7]\n",
        "y_test_filtered = np.delete(y_test_encoded, np.where(y_test_encoded == excluded_classes[0])[0])\n",
        "y_pred_filtered = np.delete(y_pred, np.where(y_test_encoded == excluded_classes[0])[0])\n",
        "\n",
        "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
        "precision_filtered = precision_score(y_test_filtered, y_pred_filtered, average='macro')\n",
        "recall_filtered = recall_score(y_test_filtered, y_pred_filtered, average='macro')\n",
        "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='macro')\n",
        "\n",
        "print(\"Model Evaluation on Test Set (excluding class 7):\")\n",
        "print(f\"Accuracy: {accuracy_filtered:.4f}\")\n",
        "print(f\"Precision: {precision_filtered:.4f}\")\n",
        "print(f\"Recall: {recall_filtered:.4f}\")\n",
        "excluded_classes = [7]\n",
        "y_test_filtered = np.delete(y_test_encoded, np.where(y_test_encoded == excluded_classes[0])[0])\n",
        "y_pred_filtered = np.delete(y_pred, np.where(y_test_encoded == excluded_classes[0])[0])\n",
        "\n",
        "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
        "precision_filtered = precision_score(y_test_filtered, y_pred_filtered, average='macro')\n",
        "recall_filtered = recall_score(y_test_filtered, y_pred_filtered, average='macro')\n",
        "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='macro')\n",
        "\n",
        "print(\"Model Evaluation on Test Set (excluding class 7):\")\n",
        "print(f\"Accuracy: {accuracy_filtered:.4f}\")\n",
        "print(f\"Precision: {precision_filtered:.4f}\")\n",
        "print(f\"Recall: {recall_filtered:.4f}\")\n",
        "print(f\"F1 Score: {f1_filtered:.4f}\")\n",
        "print(\"\\nDetailed Classification Report (excluding class 7):\")\n",
        "print(classification_report(y_test_filtered, y_pred_filtered, target_names=[str(label_encoder.classes_[i]) for i in range(len(label_encoder.classes_)) if i not in excluded_classes]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UpxlhYcxDc5",
        "outputId": "cf8270ac-3070-4200-b20a-11e69116cda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation on Test Set (excluding class 7):\n",
            "Accuracy: 0.6852\n",
            "Precision: 0.6568\n",
            "Recall: 0.7190\n",
            "Model Evaluation on Test Set (excluding class 7):\n",
            "Accuracy: 0.6852\n",
            "Precision: 0.6568\n",
            "Recall: 0.7190\n",
            "F1 Score: 0.6806\n",
            "\n",
            "Detailed Classification Report (excluding class 7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       134\n",
            "           1       0.82      0.84      0.83       194\n",
            "           2       0.73      0.77      0.75       162\n",
            "           3       0.57      0.63      0.60       150\n",
            "           4       0.73      0.85      0.79       153\n",
            "           5       0.73      0.69      0.71        39\n",
            "           6       0.82      0.82      0.82       291\n",
            "           8       0.72      0.80      0.76       211\n",
            "           9       0.84      0.81      0.83        47\n",
            "          10       0.32      0.50      0.39        22\n",
            "          11       0.56      0.64      0.60       134\n",
            "          12       0.37      0.62      0.47        32\n",
            "          13       0.76      0.88      0.82       201\n",
            "          14       0.73      0.83      0.78       210\n",
            "          15       0.66      0.78      0.71        51\n",
            "          16       0.69      0.75      0.72       108\n",
            "          17       0.55      0.67      0.60       123\n",
            "          18       0.44      0.20      0.28       454\n",
            "\n",
            "    accuracy                           0.69      2716\n",
            "   macro avg       0.66      0.72      0.68      2716\n",
            "weighted avg       0.67      0.69      0.67      2716\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The improvement from eliminating relation class 7 is little."
      ],
      "metadata": {
        "id": "M-VNpzIf63TN"
      }
    }
  ]
}